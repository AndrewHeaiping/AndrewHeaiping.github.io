---
layout: post
title: "通俗地讲解CNN的工作原理"
date: 2018-09-04
description: "机器学习进阶篇"
tag: 机器学习  

---    





1.视觉感知
==========

1.1画面识别的任务
-----------------

卷积神经网络(CNN)
最初是服务于画面识别的，所以我们先来看看画面识别的实质是什么。引用一个生物学原理：**生物所看到的景象并不是世界真实的原貌，而是长期进化出来的适合自己生存环境的一种感知方式。**形象地讲，任何视觉系统都是将图像反光与脑中所看到的概念进行关联，用数学逻辑表示如下图：

![](https://pic4.zhimg.com/80/v2-2c82abd20c4e7c40f7f13f035b924b0b_hd.png)

1.2影响视觉识别的因素
---------------------

**图片被识别成什么不仅仅取决于图片本身，还取决于图片是如何被观察的。**如观察图片的角度、环境（如某些光效应导致的折射等等）、观察者的心理年龄等等因素。

2.图像表达
==========

2.1计算机“看”到的图片 
----------------------

**补充知识**：**图像在计算机中是一堆按顺序排列的数字，数字的范围是0到255，而0表示最暗，255表示最亮（如**[RGB](http://tool.oschina.net/commons?type=3)**0,0 ,0表示黑色，255,255,255为白色）。**而一张图片可以用一个长长的向量来表示，但是这样做很明显会失去图片的平面结构信息，通常的做法是选择矩阵的表示方法：28×28的矩阵。比如在RGB模型中有三个矩阵，分别代表R(红色)、G(绿色)、B(蓝色)，每一层代表一个Channel。而在电脑中，常常将一张RGB模型的图片视为数字组成的“长方体”，宽、高、深分别用width、height、depth来表示。
<br/>
![](/images/posts/markdown/d48225ed8d88cdc171d7cb636bac44f1.png)
<br/>
<center>
RGB-模型图
</center>
2.2画面不变性
-------------

什么是画面不变性？通俗来讲，对于同一个物体，不论观察该物体的角度如何，都应该被识别为同一个物体，这就是**画面不变性**。这一点对于小孩子都可以轻松做到，那么对于计算机呢？很显然要让计算机做到这一点，其实也不难。为了能够理解卷积神经网络如何做到画面不变性，先来拿出与之相反
(不支持画面不变性) 的前馈神经网络来比较。

3前馈神经网络做画面识别的不足
=============================

3.1 权值不共享
--------------

对于识别某些处于边边角角的图形时，由于前馈神经网络权值不共享，每次识别时都要先将图片的展开的列向量，对某些特定节点的权值进行调整（也就是每次都要重新学习），这样无疑会增加了计算量。如下图中识别黑色弯折图形，当处于右下角时，始终无法识别。

![](/images/posts/markdown/be6f6ed726519a06a3812be8f1c1d738.png)

解决的方案就是使不同位置的权重共享。而卷积神经网络,就是让权重在不同位置共享的神经网络。

4 CNN做画面识别
===============

4.1 局部连接
------------

在CNN中，我们通常会选取一个方形的局部区域，用来扫描整个图片，叫做**卷积核(Kernel)**或**滤波器(Filter)**。这个区域的大小(或尺寸)称为**Filter
Size**，如3×3。
这样做的好处就是，减少了每次识别的神经元连接数，更加高效，并且为后面**降维**做了贡献。

4.2空间共享
-----------

每当一个Filter扫过一个区域时，输出节点其实都是共用了权值**W**以及偏置节点b0，我们将每次Filter移动的格数称为Stride。**空间共享也就是卷积神经网络所引入的先验知识。**
<center>
![https://pic1.zhimg.com/v2-4fd0400ccebc8adb2dffe24aac163e70_b.gif](/images/posts/markdown/media/4fd0400ccebc8adb2dffe24aac163e70.gif)
</center>
4.3输出空间表达
---------------

**CNN**实际上并没有像上面这样将图片用一个列向量来表示，而是用矩阵来表示，这样做也是为了保持图片的平面结构信息**。**

如下图所示，输入为一个5×5图片矩阵，输出为一个3×3的矩阵，这个矩阵被称为卷积特征矩阵(Convolved
Feature)或特征图(Feature Map)。
<center>
![https://pic3.zhimg.com/v2-7fce29335f9b43bce1b373daa40cccba_b.gif](/images/posts/markdown/media/7fce29335f9b43bce1b373daa40cccba.gif)
</center>
4.4 Depth维的处理
-----------------

对于深度为1的灰度图形，我们已经完成了特征矩阵的提取，而图片通常是用有3个Channels的RGB模型来表示的，这个时候应该如何卷积呢？

实际上也很简单，这个过程好比切蛋糕，我们通常会将蛋糕均匀分成几个部分，然后一刀切下去，最后切成很多小立方块。这里的划分区域就是一个Filter，一刀切就是每一层都要贯穿(全连接)。需要注意的是每个小立方块中的每层所使用的权值一般都是不一样的，同时我们也可以得到每一个小立方块的节点总数为Total=Depth×Filter_Size。

每个filter会在width维,
height维上，以局部连接和空间共享，并贯串整个depth维的方式得到一个Feature Map。

4.5 Zero Padding操作
--------------------

通过上面的例子可以看出，一个4×4的图片经过2×2的filter卷积之后变成了一个3×3的Feature
Map，尺寸在原来基础上缩小了一圈，那么经过若干层卷积之后会不会没有了？答案是是肯定的。但是我们要避免这种损失，于是就引入了“**0填充**”(Zero
Padding)操作。

如下图所示，如果输入依然为4×4的图片和3×3的filter，但是我们要求经过卷积后，图片的尺寸不变，就需要在图片外围用一层0进行填充。经过推理计算，我们很容易得到任意一个尺寸的图片经过任意尺寸的Filter进行卷积之后的Feature
Map 的尺寸为：(Input_size + 2 × Padding_Size −
Filter_Size)/Stride+1，如上例，(4+2×1-3)/1+1 =
4。发现，经过卷积之后，图片的尺寸确实没被压缩。
<center>
![https://pic2.zhimg.com/80/v2-c1010eb5dcf032ea95eab495a45f9b31_hd.png](/images/posts/markdown/media/a33d33f1bce062f2a707c00a41360404.png)
</center>
4.6 形状、概念抓取
------------------

可以从下面这张图中感受到不同数值的Filters所卷积过后的Feature
Map可以探测边缘、棱角、模糊、突出等概念。filter内的权重矩阵W是网络根据数据学习得到的，也就是说，我们让神经网络自己学习以什么样的方式去观察图片。**卷积神经网络会尽可能寻找最能解释训练数据的抓取方式。**
<center>
![https://pic1.zhimg.com/80/v2-644d108587a6ce7fa471ede5d2e11e98_hd.png](/images/posts/markdown/media/d77371e9bf20a6a838e7381143318ddb.png)
</center>
4.7 多filters
-------------

**卷积层的输入是长方体，输出也是长方体。**

可以从下图看出，输入为4×4×3的长方体经过2×2的Filter卷积之后得到了一个3×3×4的长方体。这样卷积后输出的长方体可以作为新的输入送入另一个卷积层中处理。
<center>
![https://pic1.zhimg.com/80/v2-d11e1d2f2c41b6df713573f8155bc324_hd.png](/images/posts/markdown/media/eae793a9253913e2423ce000aa9f24db.png)
</center>



</br>
转载请注明：[何爱平的博客](http://AndrewHeaiping.github.io) » [点击阅读原文](https://www.heaiping.cn/2018/09/03MachineLearning_introduce/)
